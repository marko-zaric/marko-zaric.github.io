<!DOCTYPE html><!--W1wbz3urstqXQ9J9G45PI--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/051742360c26797e-s.p.102b7f24.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/5f402bd2d8eef81a-s.p.b72f0478.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="https://images.unsplash.com/photo-1667372393119-3d4c48d07fc9?w=1200&amp;h=600&amp;fit=crop" as="image"/><link rel="stylesheet" href="/_next/static/chunks/effd76132d2274ec.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/a09ab61d4fa91512.js"/><script src="/_next/static/chunks/99fb14d46fc3e0c6.js" async=""></script><script src="/_next/static/chunks/8296bf97416a5ebf.js" async=""></script><script src="/_next/static/chunks/a4eeb46e07741350.js" async=""></script><script src="/_next/static/chunks/turbopack-519e9ecc33f31c62.js" async=""></script><script src="/_next/static/chunks/7b61afccb111bc8e.js" async=""></script><script src="/_next/static/chunks/ff1a16fafef87110.js" async=""></script><script src="/_next/static/chunks/247eb132b7f7b574.js" async=""></script><script src="/_next/static/chunks/22d4426581bf32de.js" async=""></script><meta name="next-size-adjust" content=""/><title>Marko Zarić</title><meta name="description" content="Marko Zarić academic and engineering portfolio"/><link rel="icon" href="/favicon.ico?favicon.43bbbd2c.ico" sizes="32x32" type="image/x-icon"/><script src="/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="newsreader_6170adb-module__ZIJgeq__variable jetbrains_mono_13b10504-module__696lgG__variable antialiased"><div hidden=""><!--$--><!--/$--></div><div class="p-4 md:p-12 min-h-screen overflow-hidden"><div class="w-full mx-auto"><div class="max-w-3xl mx-auto"><header class="flex items-baseline justify-between"><h1 class="text-2xl font-serif">MARKO ZARIĆ</h1><nav class="flex gap-6"><a class="font-mono text-sm underline underline-offset-8 transition-colors hover:decoration-2 hover:text-black/70" href="/">Home</a><a class="font-mono text-sm underline underline-offset-8 transition-colors hover:decoration-2 hover:text-black/70" href="/research">Research</a></nav></header><main class="mt-16"><a class="font-mono text-sm text-foreground/60 hover:text-foreground mb-8 inline-block" href="/blog">← Back to blog</a><article class="mt-8"><header class="mb-12"><h1 class="text-4xl md:text-5xl font-serif mb-4">Building Scalable ML Pipelines with Kubernetes</h1><div class="flex flex-wrap gap-4 font-mono text-sm text-foreground/60"><time>Nov 15, 2024</time><span>•</span><span>12 min read</span><span>•</span><span>Marko Zaric</span></div></header><div class="prose prose-lg max-w-none"><p class="mb-6 text-foreground/90 leading-relaxed">Machine learning infrastructure has evolved dramatically over the past few years. As models become more complex and data volumes grow exponentially, the need for robust, scalable deployment solutions has never been more critical. In this post, I&#x27;ll share my experience building and deploying ML pipelines using Kubernetes orchestration.</p>
<h2 class="text-2xl md:text-3xl font-serif mt-12 mb-6">The Challenge of Scale</h2>
<p class="mb-6 text-foreground/90 leading-relaxed">When deploying machine learning models in production, we face several key challenges: maintaining model versioning, ensuring reproducibility, handling varying computational loads, and orchestrating complex workflows that span data preprocessing, model training, and inference serving.</p>
<figure><img src="https://images.unsplash.com/photo-1667372393119-3d4c48d07fc9?w=1200&amp;h=600&amp;fit=crop" alt="Kubernetes cluster visualization"/><figcaption>A typical Kubernetes cluster architecture for ML workloads</figcaption></figure>
<h2 class="text-2xl md:text-3xl font-serif mt-12 mb-6">Why Kubernetes?</h2>
<p class="mb-6 text-foreground/90 leading-relaxed">Kubernetes provides container orchestration at scale, which is perfect for ML workflows. It offers automatic scaling, self-healing capabilities, and declarative configuration that makes infrastructure reproducible. Combined with tools like Kubeflow and MLflow, we can build end-to-end ML platforms that handle everything from experimentation to production deployment.</p>
<figure class="my-8"><pre class="my-6 p-4 bg-neutral-100 border border-black overflow-x-auto rounded"><code class="font-mono text-sm"><span data-line=""><span style="color:#22863A">apiVersion</span><span style="color:#24292E">: </span><span style="color:#032F62">batch/v1</span></span>
<span data-line=""><span style="color:#22863A">kind</span><span style="color:#24292E">: </span><span style="color:#032F62">Job</span></span>
<span data-line=""><span style="color:#22863A">metadata</span><span style="color:#24292E">:</span></span>
<span data-line=""><span style="color:#22863A">  name</span><span style="color:#24292E">: </span><span style="color:#032F62">ml-training-job</span></span>
<span data-line=""><span style="color:#22863A">spec</span><span style="color:#24292E">:</span></span>
<span data-line=""><span style="color:#22863A">  template</span><span style="color:#24292E">:</span></span>
<span data-line=""><span style="color:#22863A">    spec</span><span style="color:#24292E">:</span></span>
<span data-line=""><span style="color:#22863A">      containers</span><span style="color:#24292E">:</span></span>
<span data-line=""><span style="color:#24292E">      - </span><span style="color:#22863A">name</span><span style="color:#24292E">: </span><span style="color:#032F62">training</span></span>
<span data-line=""><span style="color:#22863A">        image</span><span style="color:#24292E">: </span><span style="color:#032F62">ml-model:latest</span></span>
<span data-line=""><span style="color:#22863A">        resources</span><span style="color:#24292E">:</span></span>
<span data-line=""><span style="color:#22863A">          limits</span><span style="color:#24292E">:</span></span>
<span data-line=""><span style="color:#22863A">            nvidia.com/gpu</span><span style="color:#24292E">: </span><span style="color:#005CC5">2</span></span>
<span data-line=""><span style="color:#22863A">          requests</span><span style="color:#24292E">:</span></span>
<span data-line=""><span style="color:#22863A">            memory</span><span style="color:#24292E">: </span><span style="color:#032F62">&quot;16Gi&quot;</span></span>
<span data-line=""><span style="color:#22863A">            cpu</span><span style="color:#24292E">: </span><span style="color:#032F62">&quot;4&quot;</span></span></code></pre></figure>
<p class="mb-6 text-foreground/90 leading-relaxed">The configuration above shows a simple Kubernetes job for model training. It requests 2 GPUs and 16GB of memory, demonstrating how easy it is to specify resource requirements declaratively.</p>
<p class="mb-6 text-foreground/90 leading-relaxed"><img alt="Data pipeline visualization" loading="lazy" width="1200" height="600" decoding="async" data-nimg="1" class="w-full h-auto border border-black" style="color:transparent;object-fit:cover;max-height:400px" src="https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=1200&amp;h=600&amp;fit=crop"/></p>
<h2 class="text-2xl md:text-3xl font-serif mt-12 mb-6">Best Practices</h2>
<ul class="my-6 space-y-2 list-disc list-inside">
<li class="text-foreground/90">Use separate namespaces for different stages (dev, staging, prod)</li>
<li class="text-foreground/90">Implement proper resource quotas to prevent resource exhaustion</li>
<li class="text-foreground/90">Leverage Horizontal Pod Autoscaling for inference endpoints</li>
<li class="text-foreground/90">Use persistent volumes for model artifacts and training data</li>
<li class="text-foreground/90">Implement proper monitoring with Prometheus and Grafana</li>
<li class="text-foreground/90">Set up automated rollbacks for failed deployments</li>
</ul>
<p class="mb-6 text-foreground/90 leading-relaxed">Through careful planning and leveraging Kubernetes&#x27; native capabilities, we&#x27;ve been able to reduce deployment time from hours to minutes, while improving reliability and making our ML infrastructure truly scalable.</p></div></article><div class="mt-16 pt-8 border-t border-black"><a class="font-mono text-sm text-foreground/60 hover:text-foreground" href="/blog">← Back to all posts</a></div></main><footer class="border-t border-black mt-20 py-4 flex flex-col md:flex-row justify-between items-start md:items-baseline gap-4"><span class="font-serif text-md">Interested in working with me?</span><div class="flex gap-4 font-mono text-md"><a href="mailto:marko.zaric@tue.mpg.de" class="underline underline-offset-4 hover:decoration-2 hover:text-black/70">Email</a><a href="https://linkedin.com/in/marko-zaric" target="_blank" rel="noopener noreferrer" class="underline underline-offset-4 hover:decoration-2 hover:text-black/70">LinkedIn</a></div></footer><!--$--><!--/$--></div></div></div><script src="/_next/static/chunks/a09ab61d4fa91512.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[70119,[\"/_next/static/chunks/7b61afccb111bc8e.js\"],\"default\"]\n3:I[39756,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"default\"]\n4:I[37457,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"default\"]\n6:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"OutletBoundary\"]\n7:\"$Sreact.suspense\"\n9:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"ViewportBoundary\"]\nb:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"MetadataBoundary\"]\nd:I[68027,[],\"default\"]\n:HL[\"/_next/static/chunks/effd76132d2274ec.css\",\"style\"]\n:HL[\"/_next/static/media/051742360c26797e-s.p.102b7f24.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/5f402bd2d8eef81a-s.p.b72f0478.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"W1wbz3urstqXQ9J9G45PI\",\"c\":[\"\",\"blog\",\"ml-pipelines-kubernetes\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"ml-pipelines-kubernetes\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/effd76132d2274ec.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/7b61afccb111bc8e.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"newsreader_6170adb-module__ZIJgeq__variable jetbrains_mono_13b10504-module__696lgG__variable antialiased\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-4 md:p-12 min-h-screen overflow-hidden\",\"children\":[\"$\",\"div\",null,{\"className\":\"w-full mx-auto\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-3xl mx-auto\",\"children\":[[\"$\",\"$L2\",null,{}],[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}]}]}]}]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[\"$L5\",[[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/22d4426581bf32de.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"$L6\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@8\"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L9\",null,{\"children\":\"$@a\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$Lb\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.Metadata\",\"children\":\"$@c\"}]}]}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$d\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"e:I[22016,[\"/_next/static/chunks/7b61afccb111bc8e.js\",\"/_next/static/chunks/22d4426581bf32de.js\"],\"\"]\n:HL[\"https://images.unsplash.com/photo-1667372393119-3d4c48d07fc9?w=1200\u0026h=600\u0026fit=crop\",\"image\"]\n"])</script><script>self.__next_f.push([1,"5:[[\"$\",\"main\",null,{\"className\":\"mt-16\",\"children\":[[\"$\",\"$Le\",null,{\"href\":\"/blog\",\"className\":\"font-mono text-sm text-foreground/60 hover:text-foreground mb-8 inline-block\",\"children\":\"← Back to blog\"}],[\"$\",\"article\",null,{\"className\":\"mt-8\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-12\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-4xl md:text-5xl font-serif mb-4\",\"children\":\"Building Scalable ML Pipelines with Kubernetes\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-4 font-mono text-sm text-foreground/60\",\"children\":[[\"$\",\"time\",null,{\"children\":\"Nov 15, 2024\"}],[\"$\",\"span\",null,{\"children\":\"•\"}],[\"$\",\"span\",null,{\"children\":\"12 min read\"}],[\"$\",\"span\",null,{\"children\":\"•\"}],[\"$\",\"span\",null,{\"children\":\"Marko Zaric\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"prose prose-lg max-w-none\",\"children\":[[\"$\",\"p\",null,{\"className\":\"mb-6 text-foreground/90 leading-relaxed\",\"children\":\"Machine learning infrastructure has evolved dramatically over the past few years. As models become more complex and data volumes grow exponentially, the need for robust, scalable deployment solutions has never been more critical. In this post, I'll share my experience building and deploying ML pipelines using Kubernetes orchestration.\"}],\"\\n\",[\"$\",\"h2\",null,{\"className\":\"text-2xl md:text-3xl font-serif mt-12 mb-6\",\"children\":\"The Challenge of Scale\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"mb-6 text-foreground/90 leading-relaxed\",\"children\":\"When deploying machine learning models in production, we face several key challenges: maintaining model versioning, ensuring reproducibility, handling varying computational loads, and orchestrating complex workflows that span data preprocessing, model training, and inference serving.\"}],\"\\n\",[\"$\",\"figure\",null,{\"children\":[[\"$\",\"img\",null,{\"src\":\"https://images.unsplash.com/photo-1667372393119-3d4c48d07fc9?w=1200\u0026h=600\u0026fit=crop\",\"alt\":\"Kubernetes cluster visualization\"}],[\"$\",\"figcaption\",null,{\"children\":\"A typical Kubernetes cluster architecture for ML workloads\"}]]}],\"\\n\",[\"$\",\"h2\",null,{\"className\":\"text-2xl md:text-3xl font-serif mt-12 mb-6\",\"children\":\"Why Kubernetes?\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"mb-6 text-foreground/90 leading-relaxed\",\"children\":\"Kubernetes provides container orchestration at scale, which is perfect for ML workflows. It offers automatic scaling, self-healing capabilities, and declarative configuration that makes infrastructure reproducible. Combined with tools like Kubeflow and MLflow, we can build end-to-end ML platforms that handle everything from experimentation to production deployment.\"}],\"\\n\",[\"$\",\"figure\",null,{\"className\":\"my-8\",\"children\":[\"$\",\"pre\",null,{\"className\":\"my-6 p-4 bg-neutral-100 border border-black overflow-x-auto rounded\",\"children\":[\"$\",\"code\",null,{\"className\":\"font-mono text-sm\",\"children\":[[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#22863A\"},\"children\":\"apiVersion\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#24292E\"},\"children\":\": \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#032F62\"},\"children\":\"batch/v1\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#22863A\"},\"children\":\"kind\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#24292E\"},\"children\":\": \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#032F62\"},\"children\":\"Job\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#22863A\"},\"children\":\"metadata\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#24292E\"},\"children\":\":\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#22863A\"},\"children\":\"  name\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#24292E\"},\"children\":\": \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#032F62\"},\"children\":\"ml-training-job\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#22863A\"},\"children\":\"spec\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#24292E\"},\"children\":\":\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#22863A\"},\"children\":\"  template\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#24292E\"},\"children\":\":\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#22863A\"},\"children\":\"    spec\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#24292E\"},\"children\":\":\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$Lf\",\"$L10\"]}],\"\\n\",\"$L11\",\"\\n\",\"$L12\",\"\\n\",\"$L13\",\"\\n\",\"$L14\",\"\\n\",\"$L15\",\"\\n\",\"$L16\",\"\\n\",\"$L17\",\"\\n\",\"$L18\"]}]}]}],\"\\n\",\"$L19\",\"\\n\",\"$L1a\",\"\\n\",\"$L1b\",\"\\n\",\"$L1c\",\"\\n\",\"$L1d\"]}]]}],\"$L1e\"]}],\"$L1f\"]\n"])</script><script>self.__next_f.push([1,"20:I[5500,[\"/_next/static/chunks/7b61afccb111bc8e.js\",\"/_next/static/chunks/22d4426581bf32de.js\"],\"Image\"]\nf:[\"$\",\"span\",null,{\"style\":{\"color\":\"#22863A\"},\"children\":\"      containers\"}]\n10:[\"$\",\"span\",null,{\"style\":{\"color\":\"#24292E\"},\"children\":\":\"}]\n11:[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#24292E\"},\"children\":\"      - \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#22863A\"},\"children\":\"name\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#24292E\"},\"children\":\": \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#032F62\"},\"children\":\"training\"}]]}]\n12:[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#22863A\"},\"children\":\"        image\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#24292E\"},\"children\":\": \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#032F62\"},\"children\":\"ml-model:latest\"}]]}]\n13:[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#22863A\"},\"children\":\"        resources\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#24292E\"},\"children\":\":\"}]]}]\n14:[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#22863A\"},\"children\":\"          limits\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#24292E\"},\"children\":\":\"}]]}]\n15:[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#22863A\"},\"children\":\"            nvidia.com/gpu\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#24292E\"},\"children\":\": \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#005CC5\"},\"children\":\"2\"}]]}]\n16:[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#22863A\"},\"children\":\"          requests\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#24292E\"},\"children\":\":\"}]]}]\n17:[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#22863A\"},\"children\":\"            memory\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#24292E\"},\"children\":\": \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#032F62\"},\"children\":\"\\\"16Gi\\\"\"}]]}]\n18:[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#22863A\"},\"children\":\"            cpu\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#24292E\"},\"children\":\": \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#032F62\"},\"children\":\"\\\"4\\\"\"}]]}]\n19:[\"$\",\"p\",null,{\"className\":\"mb-6 text-foreground/90 leading-relaxed\",\"children\":\"The configuration above shows a simple Kubernetes job for model training. It requests 2 GPUs and 16GB of memory, demonstrating how easy it is to specify resource requirements declaratively.\"}]\n1a:[\"$\",\"p\",null,{\"className\":\"mb-6 text-foreground/90 leading-relaxed\",\"children\":[\"$\",\"$L20\",null,{\"src\":\"https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=1200\u0026h=600\u0026fit=crop\",\"alt\":\"Data pipeline visualization\",\"width\":1200,\"height\":600,\"className\":\"w-full h-auto border border-black\",\"style\":{\"objectFit\":\"cover\",\"maxHeight\":\"400px\"}}]}]\n1b:[\"$\",\"h2\",null,{\"className\":\"text-2xl md:text-3xl font-serif mt-12 mb-6\",\"children\":\"Best Practices\"}]\n1c:[\"$\",\"ul\",null,{\"className\":\"my-6 space-y-2 list-disc list-inside\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"className\":\"text-foreground/90\",\"children\":\"Use separate namespaces for different stages (dev, staging, prod)\"}],\"\\n\",[\"$\",\"li\",null,{\"className\":\"text-foreground/90\",\"children\":\"Implement proper resource quotas to prevent resource exhaustion\"}],\"\\n\",[\"$\",\"li\",null,{\"className\":\"text-foreground/90\",\"children\":\"Leverage Horizontal Pod Autoscaling for inference endpoints\"}],\"\\n\",[\"$\",\"li\",null,{\"className\":\"text-foreground/90\",\"children\":\"Use persistent volumes for model artifacts and training data\"}],\"\\n\",[\"$\",\"li\",null,{\"className\":\"text-foreground/90\",\"children\":\"Implement proper monitoring with Prometheus and Grafana\"}],\"\\n\",[\"$\",\"li\",null,{\"className\":\"text-foreground/90\",\"children\":\"Set up automated rollbacks for failed deployments\"}],\"\\n\"]}]\n1d:[\"$\",\"p\",null,{\"className\":\"mb-6 text-foreground/90 leading-relaxed\",\"children\":\"Through careful planning and leveraging Kubernetes' native capabilities, we've been able to reduce deployment time from hours to minutes, while improving reliability and making our ML infrastructure truly "])</script><script>self.__next_f.push([1,"scalable.\"}]\n1e:[\"$\",\"div\",null,{\"className\":\"mt-16 pt-8 border-t border-black\",\"children\":[\"$\",\"$Le\",null,{\"href\":\"/blog\",\"className\":\"font-mono text-sm text-foreground/60 hover:text-foreground\",\"children\":\"← Back to all posts\"}]}]\n1f:[\"$\",\"footer\",null,{\"className\":\"border-t border-black mt-20 py-4 flex flex-col md:flex-row justify-between items-start md:items-baseline gap-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"font-serif text-md\",\"children\":\"Interested in working with me?\"}],[\"$\",\"div\",null,{\"className\":\"flex gap-4 font-mono text-md\",\"children\":[[\"$\",\"a\",null,{\"href\":\"mailto:marko.zaric@tue.mpg.de\",\"className\":\"underline underline-offset-4 hover:decoration-2 hover:text-black/70\",\"children\":\"Email\"}],[\"$\",\"a\",null,{\"href\":\"https://linkedin.com/in/marko-zaric\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"underline underline-offset-4 hover:decoration-2 hover:text-black/70\",\"children\":\"LinkedIn\"}]]}]]}]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"21:I[27201,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"IconMark\"]\nc:[[\"$\",\"title\",\"0\",{\"children\":\"Marko Zarić\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Marko Zarić academic and engineering portfolio\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/favicon.ico?favicon.43bbbd2c.ico\",\"sizes\":\"32x32\",\"type\":\"image/x-icon\"}],[\"$\",\"$L21\",\"3\",{}]]\n8:null\n"])</script></body></html>