1:"$Sreact.fragment"
2:I[22016,["/_next/static/chunks/7b61afccb111bc8e.js","/_next/static/chunks/22d4426581bf32de.js"],""]
15:I[5500,["/_next/static/chunks/7b61afccb111bc8e.js","/_next/static/chunks/22d4426581bf32de.js"],"Image"]
16:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"OutletBoundary"]
17:"$Sreact.suspense"
:HL["https://images.unsplash.com/photo-1667372393119-3d4c48d07fc9?w=1200&h=600&fit=crop","image"]
0:{"buildId":"W1wbz3urstqXQ9J9G45PI","rsc":["$","$1","c",{"children":[[["$","main",null,{"className":"mt-16","children":[["$","$L2",null,{"href":"/blog","className":"font-mono text-sm text-foreground/60 hover:text-foreground mb-8 inline-block","children":"← Back to blog"}],["$","article",null,{"className":"mt-8","children":[["$","header",null,{"className":"mb-12","children":[["$","h1",null,{"className":"text-4xl md:text-5xl font-serif mb-4","children":"Building Scalable ML Pipelines with Kubernetes"}],["$","div",null,{"className":"flex flex-wrap gap-4 font-mono text-sm text-foreground/60","children":[["$","time",null,{"children":"Nov 15, 2024"}],["$","span",null,{"children":"•"}],["$","span",null,{"children":"12 min read"}],["$","span",null,{"children":"•"}],["$","span",null,{"children":"Marko Zaric"}]]}]]}],["$","div",null,{"className":"prose prose-lg max-w-none","children":[["$","p",null,{"className":"mb-6 text-foreground/90 leading-relaxed","children":"Machine learning infrastructure has evolved dramatically over the past few years. As models become more complex and data volumes grow exponentially, the need for robust, scalable deployment solutions has never been more critical. In this post, I'll share my experience building and deploying ML pipelines using Kubernetes orchestration."}],"\n",["$","h2",null,{"className":"text-2xl md:text-3xl font-serif mt-12 mb-6","children":"The Challenge of Scale"}],"\n",["$","p",null,{"className":"mb-6 text-foreground/90 leading-relaxed","children":"When deploying machine learning models in production, we face several key challenges: maintaining model versioning, ensuring reproducibility, handling varying computational loads, and orchestrating complex workflows that span data preprocessing, model training, and inference serving."}],"\n",["$","figure",null,{"children":[["$","img",null,{"src":"https://images.unsplash.com/photo-1667372393119-3d4c48d07fc9?w=1200&h=600&fit=crop","alt":"Kubernetes cluster visualization"}],["$","figcaption",null,{"children":"A typical Kubernetes cluster architecture for ML workloads"}]]}],"\n",["$","h2",null,{"className":"text-2xl md:text-3xl font-serif mt-12 mb-6","children":"Why Kubernetes?"}],"\n",["$","p",null,{"className":"mb-6 text-foreground/90 leading-relaxed","children":"Kubernetes provides container orchestration at scale, which is perfect for ML workflows. It offers automatic scaling, self-healing capabilities, and declarative configuration that makes infrastructure reproducible. Combined with tools like Kubeflow and MLflow, we can build end-to-end ML platforms that handle everything from experimentation to production deployment."}],"\n",["$","figure",null,{"className":"my-8","children":["$","pre",null,{"className":"my-6 p-4 bg-neutral-100 border border-black overflow-x-auto rounded","children":["$","code",null,{"className":"font-mono text-sm","children":[["$","span",null,{"data-line":"","children":[["$","span",null,{"style":{"color":"#22863A"},"children":"apiVersion"}],["$","span",null,{"style":{"color":"#24292E"},"children":": "}],["$","span",null,{"style":{"color":"#032F62"},"children":"batch/v1"}]]}],"\n",["$","span",null,{"data-line":"","children":[["$","span",null,{"style":{"color":"#22863A"},"children":"kind"}],["$","span",null,{"style":{"color":"#24292E"},"children":": "}],["$","span",null,{"style":{"color":"#032F62"},"children":"Job"}]]}],"\n",["$","span",null,{"data-line":"","children":[["$","span",null,{"style":{"color":"#22863A"},"children":"metadata"}],["$","span",null,{"style":{"color":"#24292E"},"children":":"}]]}],"\n",["$","span",null,{"data-line":"","children":[["$","span",null,{"style":{"color":"#22863A"},"children":"  name"}],["$","span",null,{"style":{"color":"#24292E"},"children":": "}],["$","span",null,{"style":{"color":"#032F62"},"children":"ml-training-job"}]]}],"\n",["$","span",null,{"data-line":"","children":[["$","span",null,{"style":{"color":"#22863A"},"children":"spec"}],["$","span",null,{"style":{"color":"#24292E"},"children":":"}]]}],"\n",["$","span",null,{"data-line":"","children":[["$","span",null,{"style":{"color":"#22863A"},"children":"  template"}],["$","span",null,{"style":{"color":"#24292E"},"children":":"}]]}],"\n",["$","span",null,{"data-line":"","children":[["$","span",null,{"style":{"color":"#22863A"},"children":"    spec"}],["$","span",null,{"style":{"color":"#24292E"},"children":":"}]]}],"\n","$L3","\n","$L4","\n","$L5","\n","$L6","\n","$L7","\n","$L8","\n","$L9","\n","$La","\n","$Lb"]}]}]}],"\n","$Lc","\n","$Ld","\n","$Le","\n","$Lf","\n","$L10"]}]]}],"$L11"]}],"$L12"],["$L13"],"$L14"]}],"loading":null,"isPartial":false}
3:["$","span",null,{"data-line":"","children":[["$","span",null,{"style":{"color":"#22863A"},"children":"      containers"}],["$","span",null,{"style":{"color":"#24292E"},"children":":"}]]}]
4:["$","span",null,{"data-line":"","children":[["$","span",null,{"style":{"color":"#24292E"},"children":"      - "}],["$","span",null,{"style":{"color":"#22863A"},"children":"name"}],["$","span",null,{"style":{"color":"#24292E"},"children":": "}],["$","span",null,{"style":{"color":"#032F62"},"children":"training"}]]}]
5:["$","span",null,{"data-line":"","children":[["$","span",null,{"style":{"color":"#22863A"},"children":"        image"}],["$","span",null,{"style":{"color":"#24292E"},"children":": "}],["$","span",null,{"style":{"color":"#032F62"},"children":"ml-model:latest"}]]}]
6:["$","span",null,{"data-line":"","children":[["$","span",null,{"style":{"color":"#22863A"},"children":"        resources"}],["$","span",null,{"style":{"color":"#24292E"},"children":":"}]]}]
7:["$","span",null,{"data-line":"","children":[["$","span",null,{"style":{"color":"#22863A"},"children":"          limits"}],["$","span",null,{"style":{"color":"#24292E"},"children":":"}]]}]
8:["$","span",null,{"data-line":"","children":[["$","span",null,{"style":{"color":"#22863A"},"children":"            nvidia.com/gpu"}],["$","span",null,{"style":{"color":"#24292E"},"children":": "}],["$","span",null,{"style":{"color":"#005CC5"},"children":"2"}]]}]
9:["$","span",null,{"data-line":"","children":[["$","span",null,{"style":{"color":"#22863A"},"children":"          requests"}],["$","span",null,{"style":{"color":"#24292E"},"children":":"}]]}]
a:["$","span",null,{"data-line":"","children":[["$","span",null,{"style":{"color":"#22863A"},"children":"            memory"}],["$","span",null,{"style":{"color":"#24292E"},"children":": "}],["$","span",null,{"style":{"color":"#032F62"},"children":"\"16Gi\""}]]}]
b:["$","span",null,{"data-line":"","children":[["$","span",null,{"style":{"color":"#22863A"},"children":"            cpu"}],["$","span",null,{"style":{"color":"#24292E"},"children":": "}],["$","span",null,{"style":{"color":"#032F62"},"children":"\"4\""}]]}]
c:["$","p",null,{"className":"mb-6 text-foreground/90 leading-relaxed","children":"The configuration above shows a simple Kubernetes job for model training. It requests 2 GPUs and 16GB of memory, demonstrating how easy it is to specify resource requirements declaratively."}]
d:["$","p",null,{"className":"mb-6 text-foreground/90 leading-relaxed","children":["$","$L15",null,{"src":"https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=1200&h=600&fit=crop","alt":"Data pipeline visualization","width":1200,"height":600,"className":"w-full h-auto border border-black","style":{"objectFit":"cover","maxHeight":"400px"}}]}]
e:["$","h2",null,{"className":"text-2xl md:text-3xl font-serif mt-12 mb-6","children":"Best Practices"}]
f:["$","ul",null,{"className":"my-6 space-y-2 list-disc list-inside","children":["\n",["$","li",null,{"className":"text-foreground/90","children":"Use separate namespaces for different stages (dev, staging, prod)"}],"\n",["$","li",null,{"className":"text-foreground/90","children":"Implement proper resource quotas to prevent resource exhaustion"}],"\n",["$","li",null,{"className":"text-foreground/90","children":"Leverage Horizontal Pod Autoscaling for inference endpoints"}],"\n",["$","li",null,{"className":"text-foreground/90","children":"Use persistent volumes for model artifacts and training data"}],"\n",["$","li",null,{"className":"text-foreground/90","children":"Implement proper monitoring with Prometheus and Grafana"}],"\n",["$","li",null,{"className":"text-foreground/90","children":"Set up automated rollbacks for failed deployments"}],"\n"]}]
10:["$","p",null,{"className":"mb-6 text-foreground/90 leading-relaxed","children":"Through careful planning and leveraging Kubernetes' native capabilities, we've been able to reduce deployment time from hours to minutes, while improving reliability and making our ML infrastructure truly scalable."}]
11:["$","div",null,{"className":"mt-16 pt-8 border-t border-black","children":["$","$L2",null,{"href":"/blog","className":"font-mono text-sm text-foreground/60 hover:text-foreground","children":"← Back to all posts"}]}]
12:["$","footer",null,{"className":"border-t border-black mt-20 py-4 flex flex-col md:flex-row justify-between items-start md:items-baseline gap-4","children":[["$","span",null,{"className":"font-serif text-md","children":"Interested in working with me?"}],["$","div",null,{"className":"flex gap-4 font-mono text-md","children":[["$","a",null,{"href":"mailto:marko.zaric@tue.mpg.de","className":"underline underline-offset-4 hover:decoration-2 hover:text-black/70","children":"Email"}],["$","a",null,{"href":"https://linkedin.com/in/marko-zaric","target":"_blank","rel":"noopener noreferrer","className":"underline underline-offset-4 hover:decoration-2 hover:text-black/70","children":"LinkedIn"}]]}]]}]
13:["$","script","script-0",{"src":"/_next/static/chunks/22d4426581bf32de.js","async":true}]
14:["$","$L16",null,{"children":["$","$17",null,{"name":"Next.MetadataOutlet","children":"$@18"}]}]
18:null
